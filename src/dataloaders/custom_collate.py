# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vidw1tlARtHwWWzvN-5mgpkZF99EgY9w
"""

# src/dataloaders/custom_collate.py
import torch
from torch.nn.utils.rnn import pad_sequence
from torch_geometric.data import Batch

def collate_fn_graphdta(batch):
    """
    Collate function for GraphDTADataset (Drug Graphs + Protein Sequences).
    """
    drug_graphs, protein_seqs, labels = zip(*batch)

    drug_batch = Batch.from_data_list(list(drug_graphs))

    # protein_seqs are variable-length tensors, pad them
    padded_proteins = pad_sequence(protein_seqs, batch_first=True, padding_value=0) # 0 is padding_idx

    labels_tensor = torch.stack(list(labels)).squeeze() # Ensure labels is a 1D tensor for MSELoss
    if labels_tensor.ndim == 0: # if batch size is 1
        labels_tensor = labels_tensor.unsqueeze(0)

    return drug_batch, padded_proteins, labels_tensor

def collate_fn_graphdta3d(batch):
    """
    Collate function for GraphDTA3DDataset (Drug Graphs + Protein Graphs).
    """
    drug_graphs, protein_graphs, labels = zip(*batch)

    drug_batch = Batch.from_data_list(list(drug_graphs))
    protein_batch = Batch.from_data_list(list(protein_graphs))

    labels_tensor = torch.stack(list(labels)).squeeze() # Ensure labels is a 1D tensor for MSELoss
    if labels_tensor.ndim == 0: # if batch size is 1
        labels_tensor = labels_tensor.unsqueeze(0)

    return drug_batch, protein_batch, labels_tensor