# -*- coding: utf-8 -*-
"""process_protein_sequences

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wMfbUB9eFY6LiDMObhMajVmZSNsUUAnr
"""

# src/preprocessing/process_protein_sequences.py
import os
import sys
import pandas as pd
import torch
from tqdm import tqdm
import argparse

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils.protein_utils import sequence_to_tensor, MAX_SEQ_LEN, AA_TO_IDX_SEQ

def encode_protein_sequences(sequence_series, protein_id_series, output_path):
    """
    Encodes protein sequences to tensors and saves them.
    """
    protein_tensors = {}
    print(f"Processing {len(sequence_series)} protein sequences...")

    for i in tqdm(range(len(sequence_series))):
        seq = sequence_series.iloc[i]
        prot_id = protein_id_series.iloc[i]

        if prot_id not in protein_tensors: # Process each unique protein ID once
            tensor = sequence_to_tensor(seq, max_len=MAX_SEQ_LEN, aa_to_idx_map=AA_TO_IDX_SEQ)
            protein_tensors[prot_id] = tensor

    torch.save(protein_tensors, output_path)
    print(f"Saved {len(protein_tensors)} unique protein sequence tensors to {output_path}")

def main():
    parser = argparse.ArgumentParser(description="Encode protein sequences from CSV.")
    parser.add_argument("--dataset_name", type=str, required=True, choices=["davis", "kiba"],
                        help="Name of the dataset (davis or kiba).")
    parser.add_argument("--csv_path", type=str, required=True,
                        help="Path to the input CSV file containing sequences and Protein_Index.")
    parser.add_argument("--sequence_col", type=str, required=True,
                        help="Name of the protein sequence column in the CSV.")
    parser.add_argument("--protein_id_col", type=str, required=True,
                        help="Name of the Protein_Index/ID column in the CSV.")
    parser.add_argument("--output_dir", type=str, required=True,
                        help="Directory to save the processed protein sequence tensors .pt file.")

    args = parser.parse_args()

    df = pd.read_csv(args.csv_path)

    # Get unique proteins by ID, taking the first sequence encountered for that ID
    unique_protein_df = df[[args.protein_id_col, args.sequence_col]].drop_duplicates(subset=[args.protein_id_col]).reset_index(drop=True)

    sequence_series = unique_protein_df[args.sequence_col]
    protein_id_series = unique_protein_df[args.protein_id_col]

    output_filename = f"{args.dataset_name}_protein_sequence_tensors.pt"
    output_file_path = os.path.join(args.output_dir, output_filename)
    os.makedirs(args.output_dir, exist_ok=True)

    encode_protein_sequences(sequence_series, protein_id_series, output_file_path)

if __name__ == "__main__":
    # Example command for Davis:
    # python src/preprocessing/process_protein_sequences.py --dataset_name davis --csv_path ./data/davis/proteins.csv --sequence_col Sequence --protein_id_col Protein_Index --output_dir ./data/processed/davis

    # Example command for KIBA:
    # python src/preprocessing/process_protein_sequences.py --dataset_name kiba --csv_path ./data/kiba/kiba_affinity_df.csv --sequence_col Sequence --protein_id_col Protein_Index --output_dir ./data/processed/kiba
    main()